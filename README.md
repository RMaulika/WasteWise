# WasteWise - AI/ML Internship Project (Sustainability Theme)

This project focuses on classifying waste into **Organic (O)** and **Recyclable (R)** categories using deep learning (MobileNetV2).  
It is part of the **Shellâ€“Edunet Skills4Future Internship (Octâ€“Nov 2025)** under the **Sustainability** theme.

----

## ğŸ“ Project Structure
Waste-wise/
â”‚
â”œâ”€â”€ Week1/ # Baseline model (MobileNetV2)
â”‚ â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ sample_images/
â”‚
â”œâ”€â”€ dataset/ # Original dataset (kept local)
â”œâ”€â”€ data/ # Split dataset (train/val/test)
â”œâ”€â”€ Week2/ # (Will contain fine-tuned model & augmentation)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

---

## ğŸ§  Week 1 â€“ Baseline Model

**Goal:** Build a baseline classifier using MobileNetV2 for binary waste classification.  

**Dataset:**  
- Classes: *Organic (O)* and *Recyclable (R)*
- Dataset organized into train/validation/test using a custom split script.

**Command to run:**
```bash
cd Week1
python main.py

**Outputs:**
outputs/best_model.h5
outputs/accuracy_plot.png
outputs/loss_plot.png

Week 1 Summary:
âœ… Dataset setup completed
âœ… EDA and baseline model trained (MobileNetV2)
âœ… Validation accuracy = 97.14%

---

## ğŸ—“ï¸ Week 2 â€“ Fine-Tuning & Data Augmentation

** Objective **
Improve the baseline MobileNetV2 modelâ€™s performance by:
- Fine-tuning deeper layers  
- Applying image data augmentation  
- Evaluating post-tuning accuracy and loss

** Steps Performed **
âœ… Loaded preprocessed dataset from Week 1  
âœ… Implemented data augmentation using `ImageDataGenerator` (rotation, zoom, flips)  
âœ… Unfrozen top layers of MobileNetV2 and fine-tuned with a lower learning rate  
âœ… Trained the fine-tuned model for multiple epochs  
âœ… Evaluated and saved updated metrics and plots  

**Command to Run:**
```bash
python Week2/main.py

**Outputs:**
Week2/outputs/fine_tuned_model.h5
Week2/outputs/accuracy_plot_week2.png
Week2/outputs/loss_plot_week2.png
Week2/outputs/confusion_matrix_week2.png

Week 2 Summary:
âœ…Validation accuracy (after fine-tuning): â‰ˆ 98â€“99 %
âœ…Noticeable reduction in validation loss and improved generalization

---

## Week 3 â€” Experiments, TFLite conversion & Demo

**Activities**
- Performed two fine-tuning experiments on MobileNetV2:
  - `exp1`: unfreeze last 20 layers, lr=5e-5, epochs=12 â€” validation accuracy = **0.98137**
  - `exp2`: unfreeze last 50 layers, lr=1e-4, epochs=12 â€” validation accuracy = **0.97905**
- Converted the best model to TFLite:
  - `model_opt.tflite` (post-training quant) **2.39 MB**
  - `model_int8.tflite` (full int8 quant) **2.58 MB**
- Built a simple Streamlit demo (`Week3/app.py`) to run inference locally with the saved Keras model (kept locally, not pushed).
- Saved experiment plots, confusion matrices and metrics in `Week3/outputs/exp1` and `Week3/outputs/exp2`.
- Created `Week3/outputs/summary_table.csv` comparing experiments and model sizes.

**Files / folders (important)**
- `Week3/src/convert_to_tflite.py` â€” conversion script (post-training & int8).
- `Week3/src/tflite_infer.py` â€” small script to run inference with the `.tflite`.
- `Week3/app.py` â€” Streamlit demo (requires local `Week2/outputs/best_model_week2.h5`).
- `Week3/outputs/` â€” plots, metrics and TFLite files (`model_opt.tflite`, `model_int8.tflite`).
- `Week2/outputs/best_model_week2.h5` â€” **local only** (excluded from Git).

**How to run demo (locally)**
```powershell
# activate venv
.\.venv\Scripts\activate

# run streamlit demo (uses local .h5 model)
python -m streamlit run Week3/app.py
